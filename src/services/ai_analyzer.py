"""
Servi√ßo para an√°lise de c√≥digo usando IA (OpenAI).
"""
import os
import json
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional
from openai import OpenAI
from ..domain.models import CodeAnalysis, HTMLAnalysis, Assignment
from .prompt_manager import PromptManager
from config import OPENAI_MODEL, OPENAI_MAX_TOKENS, OPENAI_TEMPERATURE
import re


class AIAnalyzer:
    """Servi√ßo para an√°lise de c√≥digo usando IA."""
    
    def __init__(self, api_key: str = None, enunciados_path: Path = None, logs_path: Path = None):
        self.api_key = api_key or os.getenv("OPENAI_API_KEY")
        if not self.api_key:
            # Busca na home do usu√°rio
            secrets_path = Path.home() / ".secrets" / "open-ai-api-key.txt"
            if secrets_path.exists():
                try:
                    self.api_key = secrets_path.read_text(encoding="utf-8").strip()
                    # Remove quebras de linha, espa√ßos e caracteres de controle
                    self.api_key = "".join(char for char in self.api_key if char.isprintable() or char == '-')
                    print(f"‚úÖ Chave da OpenAI carregada de: {secrets_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao ler chave da OpenAI em {secrets_path}: {e}")
        
        # Busca no diret√≥rio do projeto
        if not self.api_key:
            project_secrets_path = Path(".secrets") / "open-ai-api-key.txt"
            if project_secrets_path.exists():
                try:
                    self.api_key = project_secrets_path.read_text(encoding="utf-8").strip()
                    # Remove quebras de linha, espa√ßos e caracteres de controle
                    self.api_key = "".join(char for char in self.api_key if char.isprintable() or char == '-')
                    print(f"‚úÖ Chave da OpenAI carregada de: {project_secrets_path}")
                except Exception as e:
                    print(f"‚ö†Ô∏è  Erro ao ler chave da OpenAI em {project_secrets_path}: {e}")
        
        self.ai_available = bool(self.api_key)
        
        if self.ai_available:
            self.client = OpenAI(api_key=self.api_key)
            print(f"ü§ñ OpenAI API configurada com sucesso (chave: {self.api_key[:10]}...{self.api_key[-4:]})")
        else:
            print("‚ö†Ô∏è  OpenAI API key n√£o configurada. A an√°lise de IA ser√° limitada.")
        
        # Inicializa o gerenciador de prompts
        self.prompt_manager = PromptManager(enunciados_path) if enunciados_path else None
        
        # Configura√ß√£o de logs
        self.logs_path = logs_path or Path("logs")
        self.logs_path.mkdir(exist_ok=True)
        
        # Caminho para enunciados (usado para ler c√≥digo do enunciado)
        self.enunciados_path = enunciados_path
    
    def _save_ai_log(self, assignment_name: str, submission_identifier: str, 
                    analysis_type: str, prompt: str, response: str, 
                    parsed_result: Dict[str, Any]) -> None:
        """
        Salva log da an√°lise da IA para auditoria.
        
        Args:
            assignment_name: Nome do assignment
            submission_identifier: Identificador da submiss√£o (login ou grupo)
            analysis_type: Tipo de an√°lise ('python' ou 'html')
            prompt: Prompt enviado para a IA
            response: Resposta raw da IA
            parsed_result: Resultado processado da an√°lise
        """
        try:
            # Cria estrutura de diret√≥rios: logs/YYYY-MM-DD/assignment_name/
            today = datetime.now().strftime("%Y-%m-%d")
            log_dir = self.logs_path / today / assignment_name
            log_dir.mkdir(parents=True, exist_ok=True)
            
            # Nome do arquivo de log
            timestamp = datetime.now().strftime("%H-%M-%S")
            log_filename = f"{submission_identifier}_{analysis_type}_{timestamp}.json"
            log_file = log_dir / log_filename
            
            # Dados do log
            log_data = {
                "metadata": {
                    "assignment_name": assignment_name,
                    "submission_identifier": submission_identifier,
                    "analysis_type": analysis_type,
                    "timestamp": datetime.now().isoformat(),
                    "ai_model": OPENAI_MODEL
                },
                "prompt": prompt,
                "raw_response": response,
                "parsed_result": parsed_result
            }
            
            # Salva o log
            with open(log_file, 'w', encoding='utf-8') as f:
                json.dump(log_data, f, indent=2, ensure_ascii=False)
            
            print(f"üìù Log salvo: {log_file}")
            
        except Exception as e:
            print(f"‚ö†Ô∏è  Erro ao salvar log: {e}")
    
    def analyze_python_code(self, submission_path: Path, assignment: Assignment, python_execution: Optional[Any] = None, test_results: Optional[List[Any]] = None) -> CodeAnalysis:
        """Analisa c√≥digo Python usando IA com prompt espec√≠fico do assignment."""
        if not self.ai_available:
            return self._analyze_python_code_basic(submission_path, assignment)
        
        # L√™ os arquivos Python da submiss√£o
        python_files = self._read_python_files(submission_path)
        
        if not python_files:
                    return CodeAnalysis(
            score=0.0,
            score_justification="Nenhum arquivo Python encontrado para an√°lise",
            comments=["Nenhum arquivo Python encontrado"],
            issues_found=["Arquivos Python ausentes"]
        )
        
        # Constr√≥i o prompt espec√≠fico para o assignment
        if self.prompt_manager:
            prompt = self.prompt_manager.get_assignment_prompt(
                assignment=assignment,
                assignment_type="python",
                student_code=self._format_python_files(python_files),
                python_execution=python_execution,
                test_results=test_results
            )
        else:
            # Fallback para prompt gen√©rico
            prompt = self._build_python_analysis_prompt(python_files, assignment, python_execution, test_results)
        
        try:
            # Chama a API do OpenAI
            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um professor experiente de Python analisando c√≥digo de alunos. Seja construtivo e espec√≠fico, considerando os requisitos espec√≠ficos do assignment."},
                    {"role": "user", "content": prompt}
                ]
                #max_tokens=OPENAI_MAX_TOKENS,
                #temperature=OPENAI_TEMPERATURE
            )
            
            # Processa a resposta
            analysis_text = response.choices[0].message.content
            parsed_result = self._parse_python_analysis(analysis_text)
            
            # Salva log da an√°lise
            submission_identifier = submission_path.name.split('-', 1)[1] if '-' in submission_path.name else submission_path.name
            self._save_ai_log(
                assignment_name=assignment.name,
                submission_identifier=submission_identifier,
                analysis_type="python",
                prompt=prompt,
                response=analysis_text,
                parsed_result={
                    "score": parsed_result.score,
                    "score_justification": parsed_result.score_justification,
                    "comments": parsed_result.comments,
                    "suggestions": parsed_result.suggestions,
                    "issues_found": parsed_result.issues_found
                }
            )
            
            return parsed_result
            
        except Exception as e:
            return CodeAnalysis(
                score=0.0,
                score_justification=f"Erro na an√°lise de IA: {str(e)}",
                comments=[f"Erro na an√°lise de IA: {str(e)}"],
                issues_found=["Falha na an√°lise autom√°tica"]
            )
    
    def analyze_html_code(self, submission_path: Path, assignment: Assignment) -> HTMLAnalysis:
        """Analisa c√≥digo HTML usando IA com prompt espec√≠fico do assignment."""
        if not self.ai_available:
            return self._analyze_html_code_basic(submission_path, assignment)
        
        # L√™ os arquivos HTML e CSS da submiss√£o
        html_files = self._read_html_files(submission_path)
        css_files = self._read_css_files(submission_path)
        
        if not html_files:
                    return HTMLAnalysis(
            score=0.0,
            score_justification="Nenhum arquivo HTML encontrado para an√°lise",
            comments=["Nenhum arquivo HTML encontrado"],
            issues_found=["Arquivos HTML ausentes"]
        )
        
        # Constr√≥i o prompt espec√≠fico para o assignment
        if self.prompt_manager:
            prompt = self.prompt_manager.get_assignment_prompt(
                assignment=assignment,
                assignment_type="html",
                student_code=self._format_html_files(html_files, css_files)
            )
        else:
            # Fallback para prompt gen√©rico
            prompt = self._build_html_analysis_prompt(html_files, css_files, assignment)
        
        try:
            # Chama a API do OpenAI
            response = self.client.chat.completions.create(
                model=OPENAI_MODEL,
                messages=[
                    {"role": "system", "content": "Voc√™ √© um professor experiente de HTML/CSS analisando p√°ginas web de alunos. Seja construtivo e espec√≠fico, considerando os requisitos espec√≠ficos do assignment."},
                    {"role": "user", "content": prompt}
                ]
                #max_tokens=OPENAI_MAX_TOKENS,
                #temperature=OPENAI_TEMPERATURE
            )
            
            # Processa a resposta
            analysis_text = response.choices[0].message.content
            parsed_result = self._parse_html_analysis(analysis_text)
            
            # Salva log da an√°lise
            submission_identifier = submission_path.name.split('-', 1)[1] if '-' in submission_path.name else submission_path.name
            self._save_ai_log(
                assignment_name=assignment.name,
                submission_identifier=submission_identifier,
                analysis_type="html",
                prompt=prompt,
                response=analysis_text,
                parsed_result={
                    "score": parsed_result.score,
                    "required_elements": parsed_result.required_elements,
                    "comments": parsed_result.comments,
                    "suggestions": parsed_result.suggestions,
                    "issues_found": parsed_result.issues_found
                }
            )
            
            return parsed_result
            
        except Exception as e:
            return HTMLAnalysis(
                score=0.0,
                score_justification=f"Erro na an√°lise de IA: {str(e)}",
                comments=[f"Erro na an√°lise de IA: {str(e)}"],
                issues_found=["Falha na an√°lise autom√°tica"]
            )
    
    def _analyze_python_code_basic(self, submission_path: Path, assignment: Assignment) -> CodeAnalysis:
        """An√°lise b√°sica de c√≥digo Python sem IA."""
        python_files = self._read_python_files(submission_path)
        
        if not python_files:
            return CodeAnalysis(
                score=0.0,
                comments=["Nenhum arquivo Python encontrado"],
                issues_found=["Arquivos Python ausentes"]
            )
        
        # An√°lise b√°sica baseada em heur√≠sticas
        score = 5.0  # Nota base
        comments = []
        suggestions = []
        issues = []
        
        # Verifica se h√° arquivos principais
        if any("main.py" in f for f in python_files):
            score += 1.0
            comments.append("Arquivo main.py encontrado")
        else:
            issues.append("Arquivo main.py n√£o encontrado")
        
        # Verifica se h√° documenta√ß√£o
        for filename, content in python_files.items():
            if '"""' in content or "'''" in content:
                score += 0.5
                comments.append(f"Documenta√ß√£o encontrada em {filename}")
                break
        else:
            suggestions.append("Adicionar docstrings ao c√≥digo")
        
        # Verifica se h√° imports
        for filename, content in python_files.items():
            if "import " in content or "from " in content:
                score += 0.5
                comments.append(f"Imports encontrados em {filename}")
                break
        
        return CodeAnalysis(
            score=min(10.0, score),
            comments=comments,
            suggestions=suggestions,
            issues_found=issues
        )
    
    def _analyze_html_code_basic(self, submission_path: Path, assignment: Assignment) -> HTMLAnalysis:
        """An√°lise b√°sica de c√≥digo HTML sem IA."""
        html_files = self._read_html_files(submission_path)
        css_files = self._read_css_files(submission_path)
        
        if not html_files:
            return HTMLAnalysis(
                score=0.0,
                comments=["Nenhum arquivo HTML encontrado"],
                issues_found=["Arquivos HTML ausentes"]
            )
        
        # An√°lise b√°sica baseada em heur√≠sticas
        score = 5.0  # Nota base
        comments = []
        suggestions = []
        issues = []
        required_elements = {}
        
        # Verifica elementos HTML obrigat√≥rios
        for filename, content in html_files.items():
            if "<h1" in content:
                required_elements["h1"] = True
                score += 0.5
            if "<h2" in content:
                required_elements["h2"] = True
                score += 0.5
            if "<h3" in content:
                required_elements["h3"] = True
                score += 0.5
            if "<ul>" in content or "<ol>" in content:
                required_elements["lists"] = True
                score += 0.5
            if "<img" in content:
                required_elements["images"] = True
                score += 0.5
            if "<a " in content:
                required_elements["links"] = True
                score += 0.5
            if "<table" in content:
                required_elements["tables"] = True
                score += 0.5
        
        # Verifica se h√° CSS
        if css_files:
            score += 1.0
            comments.append("Arquivos CSS encontrados")
        else:
            suggestions.append("Adicionar arquivos CSS para estiliza√ß√£o")
        
        # Verifica se h√° index.html
        if any("index.html" in f for f in html_files):
            score += 0.5
            comments.append("Arquivo index.html encontrado")
        else:
            issues.append("Arquivo index.html n√£o encontrado")
        
        return HTMLAnalysis(
            score=min(10.0, score),
            required_elements=required_elements,
            comments=comments,
            suggestions=suggestions,
            issues_found=issues
        )
    
    def _read_python_files(self, submission_path: Path) -> Dict[str, str]:
        """L√™ todos os arquivos Python da submiss√£o."""
        python_files = {}
        
        for file_path in submission_path.rglob("*.py"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                python_files[str(file_path.relative_to(submission_path))] = content
            except Exception as e:
                python_files[str(file_path.relative_to(submission_path))] = f"Erro ao ler arquivo: {str(e)}"
        
        return python_files
    
    def _read_html_files(self, submission_path: Path) -> Dict[str, str]:
        """L√™ todos os arquivos HTML da submiss√£o."""
        html_files = {}
        
        for file_path in submission_path.rglob("*.html"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                html_files[str(file_path.relative_to(submission_path))] = content
            except Exception as e:
                html_files[str(file_path.relative_to(submission_path))] = f"Erro ao ler arquivo: {str(e)}"
        
        return html_files
    
    def _read_css_files(self, submission_path: Path) -> Dict[str, str]:
        """L√™ todos os arquivos CSS da submiss√£o."""
        css_files = {}
        
        for file_path in submission_path.rglob("*.css"):
            try:
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                css_files[str(file_path.relative_to(submission_path))] = content
            except Exception as e:
                css_files[str(file_path.relative_to(submission_path))] = f"Erro ao ler arquivo: {str(e)}"
        
        return css_files
    
    def _build_python_analysis_prompt(self, python_files: Dict[str, str], assignment: Assignment, python_execution: Optional[Any] = None, test_results: Optional[List[Any]] = None) -> str:
        """Constr√≥i o prompt para an√°lise de c√≥digo Python."""
        # L√™ c√≥digo do enunciado se dispon√≠vel
        enunciado_code = self._read_enunciado_code(assignment.name)
        
        prompt = f"""
Analise o c√≥digo Python abaixo para o assignment "{assignment.name}".

Descri√ß√£o do assignment:
{assignment.description}

Requisitos:
{chr(10).join(f"- {req}" for req in assignment.requirements)}

C√ìDIGO DO ENUNCIADO:
{enunciado_code}

C√ìDIGO DO ALUNO:
"""
        
        for filename, content in python_files.items():
            prompt += f"\n--- {filename} ---\n{content}\n"
        
        # Adiciona informa√ß√µes sobre a execu√ß√£o do c√≥digo se dispon√≠vel
        if python_execution:
            prompt += f"""

RESULTADO DA EXECU√á√ÉO DO C√ìDIGO:
Status: {python_execution.execution_status}
Tempo de execu√ß√£o: {python_execution.execution_time:.2f} segundos
C√≥digo de retorno: {python_execution.return_code}

Output do terminal (stdout):
{python_execution.stdout_output}

Erros do terminal (stderr):
{python_execution.stderr_output}

"""
        
        # Adiciona informa√ß√µes sobre os resultados dos testes se dispon√≠vel
        if test_results:
            prompt += f"""

RESULTADO DOS TESTES:
Total de testes: {len(test_results)}
Testes que passaram: {sum(1 for test in test_results if test.result.value == 'passed')}
Testes que falharam: {sum(1 for test in test_results if test.result.value == 'failed')}
Testes com erro: {sum(1 for test in test_results if test.result.value == 'error')}

Detalhes dos testes:
"""
            for test in test_results:
                status_emoji = "‚úÖ" if test.result.value == 'passed' else "‚ùå" if test.result.value == 'failed' else "‚ö†Ô∏è"
                prompt += f"{status_emoji} {test.test_name} ({test.result.value.upper()})"
                if test.message:
                    prompt += f" - {test.message}"
                if test.execution_time > 0:
                    prompt += f" ({test.execution_time:.3f}s)"
                prompt += "\n"
            
            prompt += "\n"
        
        # Adiciona instru√ß√µes cr√≠ticas sobre execu√ß√£o e testes
        prompt += """
=== INSTRU√á√ïES CR√çTICAS SOBRE EXECU√á√ÉO E TESTES ===

‚ö†Ô∏è **REGRA FUNDAMENTAL**: AVALIE APENAS O QUE O C√ìDIGO FAZ, N√ÉO COMO ELE FAZ!
- Sempre considere o resultado dos testes e da execu√ß√£o do c√≥digo na sua avalia√ß√£o.
- O campo "Output do terminal (stdout)" deve mostrar algo relevante. Se estiver vazio, isso indica que o programa n√£o produziu nenhuma sa√≠da, o que √© um erro l√≥gico para aplica√ß√µes de terminal.
- O campo "Erros do terminal (stderr)" deve estar vazio. Se houver mensagens aqui, o c√≥digo apresentou erros de execu√ß√£o.
- Se ambos os campos estiverem vazios, o c√≥digo rodou sem erro, mas n√£o produziu nenhuma sa√≠da ‚Äî isso deve ser considerado um problema grave, pois toda aplica√ß√£o de terminal deve exibir alguma informa√ß√£o ao usu√°rio.
- Penalize a nota e aponte como PROBLEMA se o c√≥digo n√£o mostrar nada no terminal, mesmo sem erro.

üö´ **PROIBIDO AVALIAR**:
- N√ÉO avalie se as tags HTML, classes CSS ou seletores usados no scraping est√£o "corretos" baseado no seu conhecimento sobre as p√°ginas originais
- N√ÉO critique seletores CSS espec√≠ficos como "incorretos" 
- N√ÉO sugira seletores "melhores" ou "mais corretos"
- N√ÉO avalie se a estrutura HTML extra√≠da corresponde ao que voc√™ espera da p√°gina original
- N√ÉO sugira revisar, ajustar ou corrigir seletores CSS
- Esses elementos podem mudar constantemente e N√ÉO s√£o crit√©rio de avalia√ß√£o

‚ö†Ô∏è **IMPORTANTE**: N√£o repita o mesmo problema m√∫ltiplas vezes. Se um dado n√£o foi extra√≠do corretamente, mencione apenas UMA vez como problema.

üìä **CALIBRA√á√ÉO DE NOTAS**:
- Se o c√≥digo roda, exibe output e passa nos testes, mas apenas UM campo espec√≠fico n√£o foi extra√≠do corretamente, considere uma nota entre 7-8
- Se m√∫ltiplos campos n√£o foram extra√≠dos ou o c√≥digo n√£o funciona, aplique penaliza√ß√£o maior
- Se o c√≥digo funciona perfeitamente mas tem pequenos problemas de formata√ß√£o, considere nota 9-10
- Se o c√≥digo roda sem erros
- Se exibe output no terminal
- Se passa nos testes automatizados

**LEMBRE-SE**: O que importa √© se o c√≥digo FUNCIONA e produz RESULTADO, n√£o como ele chega nesse resultado!

=== CRIT√âRIOS FUNDAMENTAIS DE AVALIA√á√ÉO ===

**DEFINI√á√ÉO DE PROBLEMAS vs SUGEST√ïES:**

**PROBLEMAS (s√≥ inclua aqui se for CR√çTICO):**
- Requisitos OBRIGAT√ìRIOS do enunciado que est√£o AUSENTES ou INCORRETOS
- Fun√ß√µes obrigat√≥rias que n√£o foram implementadas ou n√£o funcionam
- Estrutura de c√≥digo que n√£o segue o especificado no enunciado
- Funcionalidades essenciais que n√£o operam corretamente

**SUGEST√ïES (inclua aqui melhorias opcionais):**
- Melhorias de c√≥digo que n√£o s√£o obrigat√≥rias
- Otimiza√ß√µes de performance que n√£o afetam funcionalidade
- Adi√ß√µes de funcionalidades extras que enriquecem mas n√£o s√£o exigidas
- Melhorias de legibilidade ou organiza√ß√£o n√£o obrigat√≥rias
- Sugest√µes de boas pr√°ticas que n√£o s√£o requisitos

**EXEMPLOS DE CLASSIFICA√á√ÉO:**
- ‚ùå PROBLEMA: "Fun√ß√£o obrigat√≥ria n√£o foi implementada" (se for obrigat√≥ria)
- ‚úÖ SUGEST√ÉO: "Poderia adicionar mais tratamento de erros"
- ‚ùå PROBLEMA: "Estrutura de arquivos n√£o segue o especificado" (se for obrigat√≥rio)
- ‚úÖ SUGEST√ÉO: "Poderia melhorar a organiza√ß√£o do c√≥digo"

=== FORMATO DE RESPOSTA ===

Formate sua resposta EXATAMENTE assim:

NOTA: [n√∫mero de 0 a 10]
JUSTIFICATIVA: [justificativa resumida e clara da nota]

COMENTARIOS: [lista de coment√°rios sobre pontos positivos]

SUGESTOES: [lista de sugest√µes de melhoria - apenas melhorias opcionais]

PROBLEMAS: [lista de problemas encontrados - apenas requisitos obrigat√≥rios ausentes/incorretos]

=== REGRAS CR√çTICAS ===

1. **NOTA 10**: Se TODOS os requisitos obrigat√≥rios do enunciado foram cumpridos
2. **PROBLEMAS**: S√≥ inclua requisitos OBRIGAT√ìRIOS ausentes/incorretos
3. **SUGEST√ïES**: Inclua melhorias opcionais e aperfei√ßoamentos
4. **N√ÉO CONFUNDA**: Melhorias n√£o s√£o problemas, problemas s√£o falhas obrigat√≥rias
5. **BASEIE A NOTA**: Nos requisitos do enunciado, n√£o em suas prefer√™ncias pessoais

Por favor, analise o c√≥digo considerando:
1. Se o aluno seguiu a estrutura e requisitos espec√≠ficos do assignment
2. Se implementou corretamente as funcionalidades solicitadas
3. Se manteve a qualidade do c√≥digo (quando n√£o fornecido no enunciado)
4. Se adicionou valor al√©m do que foi fornecido no enunciado
"""
        
        return prompt
    
    def _build_html_analysis_prompt(self, html_files: Dict[str, str], css_files: Dict[str, str], assignment: Assignment) -> str:
        """Constr√≥i o prompt para an√°lise de c√≥digo HTML."""
        # L√™ c√≥digo do enunciado se dispon√≠vel
        enunciado_code = self._read_enunciado_code(assignment.name)
        
        prompt = f"""
Analise o c√≥digo HTML/CSS abaixo para o assignment "{assignment.name}".

Descri√ß√£o do assignment:
{assignment.description}

Requisitos:
{chr(10).join(f"- {req}" for req in assignment.requirements)}

C√ìDIGO DO ENUNCIADO:
{enunciado_code}

C√ìDIGO DO ALUNO:
"""
        
        for filename, content in html_files.items():
            prompt += f"\n--- {filename} ---\n{content}\n"
        
        if css_files:
            prompt += "\nArquivos CSS:\n"
            for filename, content in css_files.items():
                prompt += f"\n--- {filename} ---\n{content}\n"
        
        prompt += """
=== CRIT√âRIOS FUNDAMENTAIS DE AVALIA√á√ÉO ===

**DEFINI√á√ÉO DE PROBLEMAS vs SUGEST√ïES:**

**PROBLEMAS (s√≥ inclua aqui se for CR√çTICO):**
- Requisitos OBRIGAT√ìRIOS do enunciado que est√£o AUSENTES ou INCORRETOS
- Elementos HTML obrigat√≥rios que n√£o foram implementados
- Estrutura de arquivos que n√£o segue o especificado no enunciado
- Funcionalidades essenciais que n√£o funcionam

**SUGEST√ïES (inclua aqui melhorias opcionais):**
- Melhorias de design ou UX que n√£o s√£o obrigat√≥rias
- Otimiza√ß√µes de c√≥digo que n√£o afetam funcionalidade
- Adi√ß√µes de conte√∫do que enriquecem mas n√£o s√£o exigidas
- Melhorias de acessibilidade ou responsividade n√£o obrigat√≥rias
- Sugest√µes de boas pr√°ticas que n√£o s√£o requisitos

**EXEMPLOS DE CLASSIFICA√á√ÉO:**
- ‚ùå PROBLEMA: "Falta elemento HTML obrigat√≥rio" (se for obrigat√≥rio)
- ‚úÖ SUGEST√ÉO: "Poderia melhorar o design visual"
- ‚ùå PROBLEMA: "Estrutura de arquivos incorreta" (se for obrigat√≥ria)
- ‚úÖ SUGEST√ÉO: "Poderia adicionar mais responsividade"

=== FORMATO DE RESPOSTA ===

Formate sua resposta EXATAMENTE assim:

NOTA: [n√∫mero de 0 a 10]
JUSTIFICATIVA: [justificativa resumida e clara da nota]

ELEMENTOS:
- Headings (h1, h2): [Presente/Ausente]
- Lists (ul/ol): [Presente/Ausente]
- Images (img): [Presente/Ausente]
- Links (a): [Presente/Ausente]
- Tables (table): [Presente/Ausente]

COMENTARIOS: [lista de coment√°rios sobre pontos positivos]

SUGESTOES: [lista de sugest√µes de melhoria - apenas melhorias opcionais]

PROBLEMAS: [lista de problemas encontrados - apenas requisitos obrigat√≥rios ausentes/incorretos]

=== REGRAS CR√çTICAS ===

1. **NOTA 10**: Se TODOS os requisitos obrigat√≥rios do enunciado foram cumpridos
2. **PROBLEMAS**: S√≥ inclua requisitos OBRIGAT√ìRIOS ausentes/incorretos
3. **SUGEST√ïES**: Inclua melhorias opcionais e aperfei√ßoamentos
4. **N√ÉO CONFUNDA**: Melhorias n√£o s√£o problemas, problemas s√£o falhas obrigat√≥rias
5. **BASEIE A NOTA**: Nos requisitos do enunciado, n√£o em suas prefer√™ncias pessoais

Por favor, analise o c√≥digo considerando:
1. Se o aluno seguiu a estrutura e requisitos espec√≠ficos do assignment
2. Se implementou corretamente os elementos HTML/CSS solicitados
3. Se manteve a qualidade do c√≥digo (quando n√£o fornecido no enunciado)
4. Se adicionou valor al√©m do que foi fornecido no enunciado
"""
        
        return prompt
    
    def _parse_python_analysis(self, analysis_text: str) -> CodeAnalysis:
        """Processa a resposta da IA para an√°lise Python."""
        lines = analysis_text.split('\n')
        score = 0.0
        score_justification = ""
        comments = []
        suggestions = []
        issues = []
        
        current_section = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('NOTA:'):
                try:
                    score = float(line.split(':')[1].strip())
                except:
                    score = 0.0
            elif line.startswith('JUSTIFICATIVA:'):
                current_section = 'justification'
                score_justification = line.split(':', 1)[1].strip() if ':' in line else ""
            elif line.startswith('COMENTARIOS:') or line.startswith('COMENT√ÅRIOS:'):
                current_section = 'comments'
            elif line.startswith('SUGESTOES:') or line.startswith('SUGEST√ïES:'):
                current_section = 'suggestions'
            elif line.startswith('PROBLEMAS:'):
                current_section = 'issues'
            elif line and current_section and line.startswith('-'):
                item = line[1:].strip()
                if current_section == 'comments':
                    comments.append(item)
                elif current_section == 'suggestions':
                    suggestions.append(item)
                elif current_section == 'issues':
                    issues.append(item)
            elif line and current_section == 'justification' and not line.startswith('-'):
                # Continua a justificativa se n√£o for um item de lista
                if score_justification:
                    score_justification += " " + line
                else:
                    score_justification = line
        
        return CodeAnalysis(
            score=score,
            score_justification=score_justification,
            comments=comments,
            suggestions=suggestions,
            issues_found=issues
        )
    
    def _parse_html_analysis(self, analysis_text: str) -> HTMLAnalysis:
        """Processa a resposta da IA para an√°lise HTML."""
        lines = analysis_text.split('\n')
        score = 0.0
        score_justification = ""
        required_elements = {}
        comments = []
        suggestions = []
        issues = []
        
        current_section = None
        
        for line in lines:
            line = line.strip()
            if line.startswith('NOTA:'):
                try:
                    score = float(line.split(':')[1].strip())
                except:
                    score = 0.0
            elif line.startswith('JUSTIFICATIVA:'):
                current_section = 'justification'
                score_justification = line.split(':', 1)[1].strip() if ':' in line else ""
            elif line.startswith('ELEMENTOS:'):
                current_section = 'elements'
                # Processa elementos que podem estar na mesma linha ap√≥s ELEMENTOS:
                elements_text = line.split(':', 1)[1].strip() if ':' in line else ""
                if elements_text:
                    self._parse_elements_line(elements_text, required_elements)
            elif line.startswith('COMENTARIOS:') or line.startswith('COMENT√ÅRIOS:'):
                current_section = 'comments'
            elif line.startswith('SUGESTOES:') or line.startswith('SUGEST√ïES:'):
                current_section = 'suggestions'
            elif line.startswith('PROBLEMAS:'):
                current_section = 'issues'
            elif line and current_section and line.startswith('-'):
                item = line[1:].strip()
                if current_section == 'elements':
                    # Processa elementos HTML em formato de lista
                    self._parse_elements_line(item, required_elements)
                elif current_section == 'comments':
                    comments.append(item)
                elif current_section == 'suggestions':
                    suggestions.append(item)
                elif current_section == 'issues':
                    issues.append(item)
            elif line and current_section == 'justification' and not line.startswith('-'):
                # Continua a justificativa se n√£o for um item de lista
                if score_justification:
                    score_justification += " " + line
                else:
                    score_justification = line
            elif line and current_section == 'elements' and not line.startswith('-') and line:
                # Processa elementos que podem estar em linhas separadas sem h√≠fen
                self._parse_elements_line(line, required_elements)
        
        return HTMLAnalysis(
            score=score,
            score_justification=score_justification,
            required_elements=required_elements,
            comments=comments,
            suggestions=suggestions,
            issues_found=issues
        )
    
    def _parse_elements_line(self, line: str, required_elements: Dict[str, bool]) -> None:
        """Processa uma linha de elementos HTML para extrair status de presen√ßa."""
        # Remove par√™nteses e conte√∫do dentro deles
        line = re.sub(r'\([^)]*\)', '', line)
        
        # Padr√µes para detectar elementos e seus status
        element_patterns = [
            # Padr√£o: "elemento: status" ou "elemento (status)"
            (r'(\w+)\s*[:\(]\s*(presente|encontrado|sim|true|yes)', True),
            (r'(\w+)\s*[:\(]\s*(ausente|n√£o encontrado|n√£o|false|no)', False),
            # Padr√£o: "elemento" seguido de "Presente" ou "Ausente" na mesma linha
            (r'(\w+).*?(presente|encontrado|sim|true|yes)', True),
            (r'(\w+).*?(ausente|n√£o encontrado|n√£o|false|no)', False),
        ]
        
        # Mapeamento de elementos comuns
        element_mapping = {
            'h1': 'h1', 'h2': 'h2', 'h3': 'h3', 'headings': 'headings',
            'ul': 'ul', 'ol': 'ol', 'lists': 'lists', 'list': 'lists',
            'img': 'img', 'images': 'img', 'image': 'img',
            'a': 'a', 'links': 'a', 'link': 'a',
            'table': 'table', 'tables': 'table'
        }
        
        line_lower = line.lower()
        
        # Verifica padr√µes espec√≠ficos
        for pattern, status in element_patterns:
            matches = re.findall(pattern, line_lower)
            for match in matches:
                element_name = match[0].strip()
                if element_name in element_mapping:
                    mapped_element = element_mapping[element_name]
                    required_elements[mapped_element] = status
        
        # Verifica presen√ßa de elementos por palavras-chave
        if any(word in line_lower for word in ['h1', 'h2', 'h3', 'headings']):
            if 'headings' not in required_elements:
                required_elements['headings'] = True
        if any(word in line_lower for word in ['ul', 'ol', 'lists', 'list']):
            if 'lists' not in required_elements:
                required_elements['lists'] = True
        if any(word in line_lower for word in ['img', 'images', 'image']):
            if 'img' not in required_elements:
                required_elements['img'] = True
        if any(word in line_lower for word in ['a', 'links', 'link']):
            if 'a' not in required_elements:
                required_elements['a'] = True
        if any(word in line_lower for word in ['table', 'tables']):
            if 'table' not in required_elements:
                required_elements['table'] = True
    
    def _format_python_files(self, python_files: Dict[str, str]) -> str:
        """Formata arquivos Python para o prompt."""
        formatted = ""
        for filename, content in python_files.items():
            formatted += f"\n--- {filename} ---\n{content}\n"
        return formatted
    
    def _format_html_files(self, html_files: Dict[str, str], css_files: Dict[str, str]) -> str:
        """Formata arquivos HTML/CSS para o prompt."""
        formatted = "Arquivos HTML:\n"
        for filename, content in html_files.items():
            formatted += f"\n--- {filename} ---\n{content}\n"
        
        if css_files:
            formatted += "\nArquivos CSS:\n"
            for filename, content in css_files.items():
                formatted += f"\n--- {filename} ---\n{content}\n"
        
        return formatted
    
    def _read_enunciado_code(self, assignment_name: str) -> str:
        """L√™ o c√≥digo fornecido no enunciado do assignment."""
        if not self.enunciados_path:
            return "Caminho para enunciados n√£o configurado."
        
        assignment_dir = self.enunciados_path / assignment_name
        
        if not assignment_dir.exists():
            return "Diret√≥rio do assignment n√£o encontrado."
        
        code_files = []
        
        # L√™ arquivos Python
        for py_file in assignment_dir.rglob("*.py"):
            if py_file.is_file():
                try:
                    content = py_file.read_text(encoding="utf-8")
                    rel_path = py_file.relative_to(assignment_dir)
                    code_files.append(f"# {rel_path}\n{content}\n")
                except Exception as e:
                    code_files.append(f"# {rel_path} - Erro ao ler: {e}\n")
        
        # L√™ arquivos HTML
        for html_file in assignment_dir.rglob("*.html"):
            if html_file.is_file():
                try:
                    content = html_file.read_text(encoding="utf-8")
                    rel_path = html_file.relative_to(assignment_dir)
                    code_files.append(f"<!-- {rel_path} -->\n{content}\n")
                except Exception as e:
                    code_files.append(f"<!-- {rel_path} - Erro ao ler: {e} -->\n")
        
        # L√™ arquivos CSS
        for css_file in assignment_dir.rglob("*.css"):
            if css_file.is_file():
                try:
                    content = css_file.read_text(encoding="utf-8")
                    rel_path = css_file.relative_to(assignment_dir)
                    code_files.append(f"/* {rel_path} */\n{content}\n")
                except Exception as e:
                    code_files.append(f"/* {rel_path} - Erro ao ler: {e} */\n")
        
        if not code_files:
            return "Nenhum c√≥digo fornecido no enunciado (arquivos vazios ou n√£o encontrados)."
        
        return "\n".join(code_files) 