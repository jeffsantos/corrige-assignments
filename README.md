# Sistema de CorreÃ§Ã£o AutomÃ¡tica de Atividades

Sistema inteligente para correÃ§Ã£o automÃ¡tica de atividades de programaÃ§Ã£o Python e HTML usando IA (OpenAI GPT) e testes automatizados com **detalhamento por funÃ§Ã£o de teste**.

## ğŸ¯ Funcionalidades

- **AnÃ¡lise AutomÃ¡tica de CÃ³digo Python**: ExecuÃ§Ã£o de testes com pytest e anÃ¡lise qualitativa usando IA
- **Detalhamento de Testes**: Resultados individuais por funÃ§Ã£o de teste (ex: `test_parse_data_function_signature`)
- **AvaliaÃ§Ã£o de PÃ¡ginas HTML/CSS**: VerificaÃ§Ã£o de elementos obrigatÃ³rios e anÃ¡lise de qualidade
- **GeraÃ§Ã£o de RelatÃ³rios**: MÃºltiplos formatos (Console, HTML, Markdown, JSON)
- **Suporte a MÃºltiplas Turmas**: Gerenciamento de diferentes turmas e assignments
- **IntegraÃ§Ã£o com ChatGPT**: AnÃ¡lise qualitativa e feedback personalizado
- **Interface CLI**: Comando simples e intuitivo
- **Busca AutomÃ¡tica da API OpenAI**: ConfiguraÃ§Ã£o flexÃ­vel da chave da API

## ğŸ—ï¸ Arquitetura

O sistema segue uma arquitetura de **Domain-Driven Design (DDD)** com as seguintes camadas:

```
src/
â”œâ”€â”€ domain/           # Modelos de domÃ­nio
â”‚   â””â”€â”€ models.py     # Entidades e objetos de valor
â”œâ”€â”€ repositories/     # Acesso a dados
â”‚   â”œâ”€â”€ assignment_repository.py
â”‚   â””â”€â”€ submission_repository.py
â”œâ”€â”€ services/         # LÃ³gica de negÃ³cio
â”‚   â”œâ”€â”€ correction_service.py
â”‚   â”œâ”€â”€ test_executor.py      # ExecuÃ§Ã£o direta na pasta do aluno
â”‚   â””â”€â”€ ai_analyzer.py        # Busca automÃ¡tica da API OpenAI
â”œâ”€â”€ utils/            # UtilitÃ¡rios
â”‚   â””â”€â”€ report_generator.py   # RelatÃ³rios com detalhamento de testes
â””â”€â”€ main.py          # Ponto de entrada CLI
```

## ğŸ“ Estrutura do Projeto

```
corrige-assignments/
â”œâ”€â”€ enunciados/           # Enunciados dos assignments
â”‚   â”œâ”€â”€ prog1-prova-av/
â”‚   â”œâ”€â”€ prog1-tarefa-html-curriculo/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ respostas/           # SubmissÃµes dos alunos por turma
â”‚   â”œâ”€â”€ ebape-prog-aplic-barra-2025/
â”‚   â”œâ”€â”€ ebape-prog-aplic-botafogo1-2025/
â”‚   â””â”€â”€ ...
â”œâ”€â”€ src/                 # CÃ³digo fonte do sistema
â”œâ”€â”€ tests/               # Testes unitÃ¡rios
â”œâ”€â”€ reports/             # RelatÃ³rios gerados
â”œâ”€â”€ .secrets/            # Chaves de API (nÃ£o versionado)
â”œâ”€â”€ Pipfile              # DependÃªncias do projeto
â”œâ”€â”€ config.py            # ConfiguraÃ§Ãµes
â””â”€â”€ README.md            # Este arquivo
```

## ğŸš€ InstalaÃ§Ã£o e ConfiguraÃ§Ã£o

### 1. PrÃ©-requisitos

- Python 3.13+
- pipenv
- Chave de API do OpenAI (opcional, mas recomendado)

### 2. InstalaÃ§Ã£o

```bash
# Clone o repositÃ³rio
git clone https://github.com/jeffsantos/corrige-assignments.git
cd corrige-assignments

# Instale o pipenv (se nÃ£o tiver)
pip install pipenv

# Instale as dependÃªncias
pipenv install

# Ative o ambiente virtual
pipenv shell
```

### 3. ConfiguraÃ§Ã£o da API OpenAI

O sistema procura a chave da API OpenAI na seguinte ordem:

1. **VariÃ¡vel de ambiente** `OPENAI_API_KEY`
2. **Arquivo** `~/.secrets/open-ai-api-key.txt` (na home do usuÃ¡rio)
3. **Arquivo** `.secrets/open-ai-api-key.txt` (no diretÃ³rio do projeto)

#### OpÃ§Ã£o 1: VariÃ¡vel de ambiente
```bash
# Linux/macOS
export OPENAI_API_KEY="sua-chave-api-aqui"

# Windows (PowerShell)
$env:OPENAI_API_KEY="sua-chave-api-aqui"

# Windows (CMD)
set OPENAI_API_KEY=sua-chave-api-aqui
```

#### OpÃ§Ã£o 2: Arquivo na home do usuÃ¡rio
```bash
# Linux/macOS
mkdir -p ~/.secrets
echo "sua-chave-api-aqui" > ~/.secrets/open-ai-api-key.txt

# Windows
mkdir %USERPROFILE%\.secrets
echo sua-chave-api-aqui > %USERPROFILE%\.secrets\open-ai-api-key.txt
```

#### OpÃ§Ã£o 3: Arquivo no projeto
```bash
# Crie o diretÃ³rio e arquivo
mkdir .secrets
echo "sua-chave-api-aqui" > .secrets/open-ai-api-key.txt
```

**Nota**: O arquivo `.secrets/` estÃ¡ no `.gitignore` para nÃ£o ser versionado.

## ğŸ“– Uso

### Interface de Linha de Comando (CLI)

#### Comandos Principais

```bash
# Listar assignments disponÃ­veis
python -m src.main list-assignments

# Listar turmas disponÃ­veis
python -m src.main list-turmas

# Listar alunos de uma turma
python -m src.main list-students --turma ebape-prog-aplic-barra-2025

# Corrigir um assignment especÃ­fico
python -m src.main correct --assignment prog1-prova-av --turma ebape-prog-aplic-barra-2025

# Corrigir um aluno especÃ­fico
python -m src.main correct --assignment prog1-prova-av --turma ebape-prog-aplic-barra-2025 --aluno "nome-do-aluno"

# Corrigir todos os assignments de uma turma
python -m src.main correct --turma ebape-prog-aplic-barra-2025 --all-assignments

# Gerar relatÃ³rio em HTML
python -m src.main correct --assignment prog1-prova-av --turma ebape-prog-aplic-barra-2025 --output-format html

# Gerar relatÃ³rio em Markdown
python -m src.main correct --assignment prog1-prova-av --turma ebape-prog-aplic-barra-2025 --output-format markdown
```

#### OpÃ§Ãµes de SaÃ­da

- `--output-format`: console, html, markdown, json
- `--output-dir`: diretÃ³rio para salvar relatÃ³rios (padrÃ£o: reports/)
- `--all-assignments`: corrigir todos os assignments da turma

### Uso ProgramÃ¡tico

```python
from src.services.correction_service import CorrectionService
from src.utils.report_generator import ReportGenerator

# Inicializa serviÃ§os (API OpenAI serÃ¡ buscada automaticamente)
correction_service = CorrectionService(enunciados_path, respostas_path)
report_generator = ReportGenerator()

# Corrige um assignment
report = correction_service.correct_assignment(
    assignment_name="prog1-prova-av",
    turma_name="ebape-prog-aplic-barra-2025"
)

# Gera relatÃ³rio com detalhamento de testes
report_generator.generate_console_report(report)
report.save_to_file("relatorio.json")
```

## ğŸ”§ ConfiguraÃ§Ã£o

### Arquivo `config.py`

```python
# ConfiguraÃ§Ãµes da API OpenAI
OPENAI_MODEL = "gpt-3.5-turbo"
OPENAI_MAX_TOKENS = 1000
OPENAI_TEMPERATURE = 0.3

# ConfiguraÃ§Ãµes de teste
TEST_TIMEOUT = 60  # segundos (aumentado para testes complexos)

# Rubricas padrÃ£o
PYTHON_RUBRIC = {
    "funcionamento_correto": 0.4,
    "qualidade_codigo": 0.3,
    "documentacao": 0.2,
    "criatividade": 0.1
}
```

## ğŸ“Š RelatÃ³rios

O sistema gera relatÃ³rios detalhados incluindo:

### EstatÃ­sticas Gerais
- Total de submissÃµes
- Nota mÃ©dia, mÃ­nima e mÃ¡xima
- Taxa de aprovaÃ§Ã£o e excelÃªncia

### AnÃ¡lise por Aluno
- Nota final calculada
- **Detalhamento de testes por funÃ§Ã£o** (ex: `test_parse_data_function_signature`)
- Status individual de cada teste (âœ… passou, âŒ falhou, âš ï¸ erro)
- Tempo de execuÃ§Ã£o de cada teste
- Feedback da anÃ¡lise de IA
- ComentÃ¡rios e sugestÃµes

### Exemplo de RelatÃ³rio de Testes
```
ğŸ§ª Resultados dos Testes:
âœ… test_scraping.py::test_fetch_page_function_signature (0.023s)
âŒ test_scraping.py::test_parse_data_function_signature (0.045s)
âœ… test_scraping.py::test_generate_csv_function_existence (0.012s)
âœ… tests/test_app.py::test_streamlit_import (0.001s)
...
```

### Formatos de SaÃ­da
- **Console**: ExibiÃ§Ã£o colorida e formatada com detalhamento de testes
- **HTML**: RelatÃ³rio web interativo com estilos para diferentes status de teste
- **Markdown**: Documento estruturado com listas de testes
- **JSON**: Dados estruturados para processamento

## ğŸ§ª Testes

### ExecuÃ§Ã£o de Testes
O sistema executa testes **diretamente na pasta da submissÃ£o do aluno**, garantindo:
- Fidelidade total ao ambiente do aluno
- DetecÃ§Ã£o de dependÃªncias e imports
- ExecuÃ§Ã£o em contexto real

### Detalhamento de Testes
- **pytest-json-report**: Gera relatÃ³rios JSON detalhados
- **AnÃ¡lise por funÃ§Ã£o**: Cada teste individual Ã© reportado
- **Tempo de execuÃ§Ã£o**: MediÃ§Ã£o precisa do tempo de cada teste
- **Mensagens de erro**: Captura de tracebacks e erros especÃ­ficos

```bash
# Executar todos os testes
pipenv run pytest

# Executar com cobertura
pipenv run pytest --cov=src

# Executar testes especÃ­ficos
pipenv run pytest tests/test_models.py
```

## ğŸ” Exemplos de Uso

### Exemplo 1: CorreÃ§Ã£o de Assignment Python com Detalhamento

```bash
python -m src.main correct \
  --assignment prog1-prova-av \
  --turma ebape-prog-aplic-barra-2025 \
  --output-format html
```

**SaÃ­da esperada:**
```
ğŸ“Š Sistema de CorreÃ§Ã£o AutomÃ¡tica
ğŸ“ˆ Resumo EstatÃ­stico
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”“
â”ƒ MÃ©trica             â”ƒ Valor  â”ƒ
â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”©
â”‚ Total de SubmissÃµes â”‚ 1      â”‚
â”‚ Nota MÃ©dia          â”‚ 9.1    â”‚
â”‚ Taxa de AprovaÃ§Ã£o   â”‚ 100.0% â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”˜

ğŸ§ª Resultados dos Testes:
âœ… test_scraping.py::test_fetch_page_function_signature (0.023s)
âŒ test_scraping.py::test_parse_data_function_signature (0.045s)
âœ… test_scraping.py::test_generate_csv_function_existence (0.012s)
...
```

### Exemplo 2: CorreÃ§Ã£o de Assignment HTML

```bash
python -m src.main correct \
  --assignment prog1-tarefa-html-curriculo \
  --turma ebape-prog-aplic-barra-2025 \
  --output-format markdown
```

### Exemplo 3: AnÃ¡lise de Aluno EspecÃ­fico

```bash
python -m src.main correct \
  --assignment prog1-prova-av \
  --turma ebape-prog-aplic-barra-2025 \
  --aluno "prog1-prova-av-ana-clara-e-isabella"
```

## ğŸ¤– AnÃ¡lise de IA

O sistema usa a API do OpenAI para:

### AnÃ¡lise de CÃ³digo Python
- AvaliaÃ§Ã£o de qualidade do cÃ³digo
- VerificaÃ§Ã£o de boas prÃ¡ticas
- IdentificaÃ§Ã£o de problemas
- SugestÃµes de melhoria

### AnÃ¡lise de HTML/CSS
- VerificaÃ§Ã£o de elementos obrigatÃ³rios
- AvaliaÃ§Ã£o de estrutura semÃ¢ntica
- AnÃ¡lise de estilizaÃ§Ã£o
- Feedback sobre responsividade

### Busca AutomÃ¡tica da API
- ConfiguraÃ§Ã£o flexÃ­vel sem necessidade de variÃ¡veis de ambiente
- Suporte multiplataforma (Linux, macOS, Windows)
- Fallback para anÃ¡lise bÃ¡sica quando API nÃ£o estÃ¡ disponÃ­vel

## ğŸ“ CritÃ©rios de AvaliaÃ§Ã£o

### Assignments Python
- **40%**: Funcionamento correto (testes automatizados)
- **30%**: Qualidade do cÃ³digo (anÃ¡lise de IA)
- **20%**: DocumentaÃ§Ã£o
- **10%**: Criatividade

### Assignments HTML
- **40%**: Estrutura HTML
- **30%**: EstilizaÃ§Ã£o CSS
- **20%**: Responsividade
- **10%**: Criatividade

## ğŸ› ï¸ Desenvolvimento

### Estrutura de ContribuiÃ§Ã£o

1. **Domain Models**: Defina entidades e objetos de valor
2. **Repositories**: Implemente acesso a dados
3. **Services**: Adicione lÃ³gica de negÃ³cio
4. **Tests**: Escreva testes unitÃ¡rios
5. **Documentation**: Atualize documentaÃ§Ã£o

### PadrÃµes de CÃ³digo

- **Type Hints**: Use tipagem estÃ¡tica
- **Docstrings**: Documente todas as funÃ§Ãµes
- **Error Handling**: Trate exceÃ§Ãµes adequadamente
- **Testing**: Mantenha cobertura de testes alta

### Melhorias Recentes

- âœ… **Detalhamento de testes por funÃ§Ã£o**
- âœ… **ExecuÃ§Ã£o direta na pasta do aluno**
- âœ… **Busca automÃ¡tica da API OpenAI**
- âœ… **RelatÃ³rios aprimorados em mÃºltiplos formatos**
- âœ… **IntegraÃ§Ã£o com pytest-json-report**

## ğŸ“„ LicenÃ§a

Este projeto Ã© desenvolvido para uso acadÃªmico na FGV.

## ğŸ¤ ContribuiÃ§Ã£o

1. Fork o projeto
2. Crie uma branch para sua feature
3. Commit suas mudanÃ§as
4. Push para a branch
5. Abra um Pull Request

## ğŸ“ Suporte

Para dÃºvidas ou problemas:
- Abra uma issue no repositÃ³rio
- Consulte a documentaÃ§Ã£o
- Execute `python -m src.main --help` para ajuda
- Execute `python example_usage.py` para exemplos prÃ¡ticos

---

**Desenvolvido para o curso de ProgramaÃ§Ã£o Aplicada da FGV** 